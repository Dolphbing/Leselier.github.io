<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/favicon.ico?v=5.1.4">


  <link rel="mask-icon" href="/favicon.ico?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="A master student of JUN">
<meta name="keywords" content="二进制">
<meta property="og:type" content="website">
<meta property="og:title" content="Leselier&#39;s Blog">
<meta property="og:url" content="https://Leselier.github.io/page/2/index.html">
<meta property="og:site_name" content="Leselier&#39;s Blog">
<meta property="og:description" content="A master student of JUN">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Leselier&#39;s Blog">
<meta name="twitter:description" content="A master student of JUN">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://Leselier.github.io/page/2/">





  <title>Leselier's Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <a href="https://github.com/Leselier" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Leselier's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Leselier.github.io/2019/08/18/深度学习论文解读-Deep-Residual-Learning-for-Image-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leselier">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/abc.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leselier's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/18/深度学习论文解读-Deep-Residual-Learning-for-Image-Recognition/" itemprop="url">深度学习论文解读|Deep Residual Learning for Image Recognition</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-18T10:35:03+08:00">
                2019-08-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>一、基本信息</p>
<p>会议：CVPR2016    最佳论文</p>
<p>二、研究背景</p>
<p>残差网络是为了解决深度神经网络（DNN）隐藏层过多时的网络退化问题而提出。退化（degradation）问题是指：当网络隐藏层变多时，网络的准确度达到饱和然后急剧退化，而且这个退化不是由于过拟合引起的。</p>
<p><img src="/2019/08/18/深度学习论文解读-Deep-Residual-Learning-for-Image-Recognition/1.png" alt></p>
<p>三、创新点</p>
<p>解决了退化问题，简化了网络训练过程并且可以从更深的网络中获得更高的准确率，该网络能够根据输入学习残差函数而不是原始函数。</p>
<p>四、详解</p>
<p>（1）退化现象并不是由过拟合导致的，而是因为当网络很深时，模型变得越来越复杂，比相对较浅的网络更难优化。 </p>
<p>（2）引入残差学习，不再让网络中一部分堆叠的层直接去拟合 $F(x)$ ，而是 $F(x)+x$ ，网络实现上，在该堆叠的网络输入端直接加一个shortcut连接到输出端（非线形激活函数之前）。</p>
<p><img src="/2019/08/18/深度学习论文解读-Deep-Residual-Learning-for-Image-Recognition/2.png" alt></p>
<p>网络架构：</p>
<p><img src="/2019/08/18/深度学习论文解读-Deep-Residual-Learning-for-Image-Recognition/3.png" alt></p>
<p>五、实验</p>
<p>（1）ImageNet分类</p>
<p>文中比较了不同深度下的平原网络和残差网络在ImageNet数据集上的分类结果。从下图中可以看出，对于平原网络，34层的训练误差和测试误差均比18层的要高，而对于残差网络，34层的网络的性能却比18层的性能好很多。而且相对于平原网络，残差网络有着更快的收敛速度。</p>
<p><img src="/2019/08/18/深度学习论文解读-Deep-Residual-Learning-for-Image-Recognition/4.png" alt></p>
<p>（2）Cifar10分类</p>
<p>文中在cifar10数据集上对更深的网络做了类似的对比实验，并得到了一致的结论，不同的是，对于1202层和110层的残差网络，110层的结果更优于1202层，这是由于1202层的网络十分庞大，而cifar10数据集相对于ImgeNet数据集非常小，导致模型训练出现了过拟合。不过这个问题可以通过正则化的方法来解决。<br><img src="/2019/08/18/深度学习论文解读-Deep-Residual-Learning-for-Image-Recognition/5.png" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Leselier.github.io/2019/08/16/差分隐私论文解读-Differentially-Private-Releasing-via-Deep-Generative-Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leselier">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/abc.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leselier's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/16/差分隐私论文解读-Differentially-Private-Releasing-via-Deep-Generative-Model/" itemprop="url">差分隐私论文解读|Differentially Private Releasing via Deep Generative Model</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-16T11:17:32+08:00">
                2019-08-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>一、基本信息</p>
<p><img src="/2019/08/16/差分隐私论文解读-Differentially-Private-Releasing-via-Deep-Generative-Model/2.png" alt></p>
<p>二、研究背景</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Leselier.github.io/2019/08/16/读书-计算机是怎么聊天的/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leselier">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/abc.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leselier's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/16/读书-计算机是怎么聊天的/" itemprop="url">读书|计算机是怎么聊天的</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-16T11:06:20+08:00">
                2019-08-16
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>来自《知乎读书一小时》系列</p>
<h3 id="第一章：计算机是如何聊天的"><a href="#第一章：计算机是如何聊天的" class="headerlink" title="第一章：计算机是如何聊天的"></a>第一章：计算机是如何聊天的</h3><p>计算机之间想要相互交流，就需要一个网络地址来对每一台计算机进行标号，就像每一部手机需要一个号码进行通话一样。</p>
<p>任意两台计算机的网络地址放在一起进行比较，分为两种不同的情况：</p>
<h4 id="（1）相同网段的通信"><a href="#（1）相同网段的通信" class="headerlink" title="（1）相同网段的通信"></a>（1）相同网段的通信</h4><p>计算机上网需要一个IP地址、一个掩码、一个网关和一个域名服务器DNS地址</p>
<p><img src="/2019/08/16/读书-计算机是怎么聊天的/1.png" alt></p>
<p>小明的网络掩码为24，也就是二进制的24位，三个字节。</p>
<p>小明Ping小美的电脑，也就是小明Ping 10.1.1.3，它会判断是不是和自己再一个网段。</p>
<p><strong>怎么判断呢？</strong></p>
<p>用自己的掩码（3个字节）去遮掩（从左到右）10.1.1.3。$\to$ 掩码的由来</p>
<p>被遮盖的是 10.1.1 ，也就是网段号，所以一个IP地址由两部分组成：<strong>网段号+主机号</strong></p>
<p>小明发现，自己和小美处在同一个网段，网段号都是 10.1.1，在同一个网段里，那么这样事情就简单了，先检查自己的ARP缓存里是否有对方网卡的硬件地址MAC，如果有，那Ping包可以完成封装发出去。</p>
<p>如果没有，就要发个ARP广播询问对方，那么又如何确定用哪个接口来发广播？</p>
<p><strong>查找路由表</strong></p>
<p>接着，小美的电脑通过点对点单播回复小明的电脑。而且MAC会在一段时间内保存在ARP的缓存中。</p>
<h4 id="（2）不同网段的通信"><a href="#（2）不同网段的通信" class="headerlink" title="（2）不同网段的通信"></a>（2）不同网段的通信</h4><p>小明Ping小丽的电脑，用掩码得到小丽的网段号是 10.1.2，和自己的不同，所以也无法使用ARP广播来发现对方的网卡硬件地址，需要查找路由表</p>
<p><img src="/2019/08/16/读书-计算机是怎么聊天的/2.png" alt></p>
<p>前三条都没有匹配到，所以选择最后一条万能路由（所有IP包最后可以成功匹配的归宿），在这里也是小明的默认网关，小明的电脑发现网关硬件接口MAC后，把Ping包发给网关10.1.1.1，网关硬件接口接收到以太网帧后，把对应的IP包放在缓存，通知IP层来取走，接着再进行路由匹配查找（采用路由最长匹配原则）。</p>
<p>路由转发严格遵守一个规则：</p>
<p>下一跳更靠近目的地，只要把IP包发给下一跳，意味着IP包最终可以达到终点。</p>
<h4 id="（3）访问互联网"><a href="#（3）访问互联网" class="headerlink" title="（3）访问互联网"></a>（3）访问互联网</h4><p>域名解析 $\to$ 浏览器HTTP格式打包 $\to$ 三次握手连接 $\to$ TCP传输 $\to$ 服务器将自己的网页回传 $\to$ 释放TCP连接</p>
<h3 id="第二章：识别网络掩码"><a href="#第二章：识别网络掩码" class="headerlink" title="第二章：识别网络掩码"></a>第二章：识别网络掩码</h3><p>IP地址与网络掩码做[按位与]操作得到网段号</p>
<p>比如小明 10.1.1.2和255.255.255.0进行按位与操作得到10.1.1就是网段号。</p>
<p>那么10.1.1.0/24包括多少个IP地址？  0-255，一共256个IP地址。</p>
<p><strong>规律</strong>:网络掩码增加一位，比如/24 $\to$ /25， 意味着IP地址被分成2份。</p>
<p><img src="/2019/08/16/读书-计算机是怎么聊天的/3.png" alt></p>
<h3 id="第三章：如何自动获取IP地址"><a href="#第三章：如何自动获取IP地址" class="headerlink" title="第三章：如何自动获取IP地址"></a>第三章：如何自动获取IP地址</h3><p>动态主机配置协议（DHCP）</p>
<p>1、客户端发现服务器——客户端进程广播一个发现服务器的报文</p>
<p>2、服务器回复客户端——服务器从IP地址池里选择一个空闲IP地址、对应的网络掩码、缺省网关和域名服务器IP地址给客户端。</p>
<p>3、客户端请求IP参数——客户端接收到服务器的回复，接受服务器分配的IP参数并请求服务器提供的IP参数</p>
<p>4、服务器确认请求——服务器最终确认客户端的请求，以单播形式发给客户端。</p>
<p>以上的前提条件：<strong>客户端与服务器在一个广播域内。</strong></p>
<p>如果不在，可以引入<strong>DHCP中继代理</strong></p>
<p>通俗地说，DHCP中继代理就是让客户端与服务器相互发现彼此的中介结构</p>
<p><img src="/2019/08/16/读书-计算机是怎么聊天的/4.png" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Leselier.github.io/2019/08/15/读书-经济学讲义/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leselier">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/abc.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leselier's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/15/读书-经济学讲义/" itemprop="url">读书|经济学讲义</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-15T12:56:52+08:00">
                2019-08-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>《薛兆丰经济学讲义》</p>
<p>第一章 稀缺——为何商业是最大的慈善</p>
<p>-经济规律在哪里都起作用，哪怕是在战俘营里面都起作用。</p>
<p>-当别人在讨论到底是公平重要，还是效率重要的时候，学过经济学 的人明白，公平背后往往是效率的考量，不是单个人效率的考量，而是 整体社会长远发展的效率的考量。公平和效率，往往是一枚硬币的两 面。</p>
<blockquote>
<p>破窗理论：</p>
<p>一 个顽童把窗户打破了，窗户的主人就要去买玻璃，这将刺激玻璃的生 产。制造玻璃的工人完成订单以后，有了钱，就可以去买面包，面包工 人又可以去买衣服。这样就推动了一连串的生产。破窗理论的支持者 说，有破坏才有进步，多难兴邦，破坏本身就是好的。</p>
</blockquote>
<p>-行善扶贫难见成效的原因：（1）缺乏反馈机制（2）委托代理问题（3）所托非人问题（4）养懒汉效应</p>
<p>-造成稀缺的原因：（1）我们想要的东西别人也想要（2）人的需求在不断变化，不断升级</p>
<p>第二章 成本——不要只盯着钱</p>
<p>-货币成本有别于全部成本</p>
<p>-中间商赚差价，让商品价格更便宜</p>
<p>-</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Leselier.github.io/2019/08/14/基于Tensorflow的GAN生成手写数字识别/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leselier">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/abc.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leselier's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/14/基于Tensorflow的GAN生成手写数字识别/" itemprop="url">基于Tensorflow的GAN生成手写数字识别</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-14T18:57:23+08:00">
                2019-08-14
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>系统结构</p>
<p><img src="/2019/08/14/基于Tensorflow的GAN生成手写数字识别/Users\dufub\Desktop\Leselier\source\_posts\基于Tensorflow的GAN生成手写数字识别\0.png" alt></p>
<p>代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save</span><span class="params">(saver,sess,logdir,step)</span>:</span></span><br><span class="line">    <span class="comment">#保存模型</span></span><br><span class="line">    model_name = <span class="string">'model'</span></span><br><span class="line">    checkpoint_path = os.path.join(logdir, model_name) <span class="comment">#保存路径</span></span><br><span class="line">    saver.save(sess, checkpoint_path, global_step=step) <span class="comment">#保存模型</span></span><br><span class="line">    print(<span class="string">'The checkpoint has been created.'</span>)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xavier_init</span><span class="params">(size)</span>:</span> <span class="comment">#初始化参数时使用的xavier_init函数</span></span><br><span class="line">    in_dim = size[<span class="number">0</span>] </span><br><span class="line">    xavier_stddev = <span class="number">1.</span> / tf.sqrt(in_dim / <span class="number">2.</span>) <span class="comment">#初始化标准差</span></span><br><span class="line">    <span class="keyword">return</span> tf.random_normal(shape=size, stddev=xavier_stddev) <span class="comment">#初始化结果</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, <span class="number">784</span>]) <span class="comment">#X表示真的样本(即真实的手写数字)</span></span><br><span class="line"> </span><br><span class="line">D_W1 = tf.Variable(xavier_init([<span class="number">784</span>, <span class="number">128</span>])) <span class="comment">#表示使用xavier方式初始化的判别器的D_W1参数，是一个784行128列的矩阵</span></span><br><span class="line">D_b1 = tf.Variable(tf.zeros(shape=[<span class="number">128</span>])) <span class="comment">#表示全零方式初始化的判别器的D_1参数，是一个长度为128的向量</span></span><br><span class="line"> </span><br><span class="line">D_W2 = tf.Variable(xavier_init([<span class="number">128</span>, <span class="number">1</span>])) <span class="comment">#表示使用xavier方式初始化的判别器的D_W2参数，是一个128行1列的矩阵</span></span><br><span class="line">D_b2 = tf.Variable(tf.zeros(shape=[<span class="number">1</span>])) <span class="comment">##表示全零方式初始化的判别器的D_1参数，是一个长度为1的向量</span></span><br><span class="line"> </span><br><span class="line">theta_D = [D_W1, D_W2, D_b1, D_b2] <span class="comment">#theta_D表示判别器的可训练参数集合</span></span><br><span class="line"> </span><br><span class="line">Z = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, <span class="number">100</span>]) <span class="comment">#Z表示生成器的输入(在这里是噪声)，是一个N列100行的矩阵</span></span><br><span class="line"> </span><br><span class="line">G_W1 = tf.Variable(xavier_init([<span class="number">100</span>, <span class="number">128</span>])) <span class="comment">#表示使用xavier方式初始化的生成器的G_W1参数，是一个100行128列的矩阵</span></span><br><span class="line">G_b1 = tf.Variable(tf.zeros(shape=[<span class="number">128</span>])) <span class="comment">#表示全零方式初始化的生成器的G_b1参数，是一个长度为128的向量</span></span><br><span class="line"> </span><br><span class="line">G_W2 = tf.Variable(xavier_init([<span class="number">128</span>, <span class="number">784</span>])) <span class="comment">#表示使用xavier方式初始化的生成器的G_W2参数，是一个128行784列的矩阵</span></span><br><span class="line">G_b2 = tf.Variable(tf.zeros(shape=[<span class="number">784</span>])) <span class="comment">#表示全零方式初始化的生成器的G_b2参数，是一个长度为784的向量</span></span><br><span class="line"> </span><br><span class="line">theta_G = [G_W1, G_W2, G_b1, G_b2] <span class="comment">#theta_G表示生成器的可训练参数集合</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample_Z</span><span class="params">(m, n)</span>:</span> <span class="comment">#生成维度为[m, n]的随机噪声作为生成器G的输入</span></span><br><span class="line">    <span class="keyword">return</span> np.random.uniform(<span class="number">-1.</span>, <span class="number">1.</span>, size=[m, n])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(z)</span>:</span> <span class="comment">#生成器，z的维度为[N, 100]</span></span><br><span class="line">    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1) <span class="comment">#输入的随机噪声乘以G_W1矩阵加上偏置G_b1，G_h1维度为[N, 128]</span></span><br><span class="line">    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2 <span class="comment">#G_h1乘以G_W2矩阵加上偏置G_b2，G_log_prob维度为[N, 784]</span></span><br><span class="line">    G_prob = tf.nn.sigmoid(G_log_prob) <span class="comment">#G_log_prob经过一个sigmoid函数，G_prob维度为[N, 784]</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> G_prob <span class="comment">#返回G_prob</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(x)</span>:</span> <span class="comment">#判别器，x的维度为[N, 784]</span></span><br><span class="line">    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1) <span class="comment">#输入乘以D_W1矩阵加上偏置D_b1，D_h1维度为[N, 128]</span></span><br><span class="line">    D_logit = tf.matmul(D_h1, D_W2) + D_b2 <span class="comment">#D_h1乘以D_W2矩阵加上偏置D_b2，D_logit维度为[N, 1]</span></span><br><span class="line">    D_prob = tf.nn.sigmoid(D_logit) <span class="comment">#D_logit经过一个sigmoid函数，D_prob维度为[N, 1]</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> D_prob, D_logit <span class="comment">#返回D_prob, D_logit</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot</span><span class="params">(samples)</span>:</span> <span class="comment">#保存图片时使用的plot函数</span></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">4</span>, <span class="number">4</span>)) <span class="comment">#初始化一个4行4列包含16张子图像的图片</span></span><br><span class="line">    gs = gridspec.GridSpec(<span class="number">4</span>, <span class="number">4</span>) <span class="comment">#调整子图的位置</span></span><br><span class="line">    gs.update(wspace=<span class="number">0.05</span>, hspace=<span class="number">0.05</span>) <span class="comment">#置子图间的间距</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">for</span> i, sample <span class="keyword">in</span> enumerate(samples): <span class="comment">#依次将16张子图填充进需要保存的图像</span></span><br><span class="line">        ax = plt.subplot(gs[i])</span><br><span class="line">        plt.axis(<span class="string">'off'</span>)</span><br><span class="line">        ax.set_xticklabels([])</span><br><span class="line">        ax.set_yticklabels([])</span><br><span class="line">        ax.set_aspect(<span class="string">'equal'</span>)</span><br><span class="line">        plt.imshow(sample.reshape(<span class="number">28</span>, <span class="number">28</span>), cmap=<span class="string">'Greys_r'</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">return</span> fig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">G_sample = generator(Z) <span class="comment">#取得生成器的生成结果</span></span><br><span class="line">D_real, D_logit_real = discriminator(X) <span class="comment">#取得判别器判别的真实手写数字的结果</span></span><br><span class="line">D_fake, D_logit_fake = discriminator(G_sample) <span class="comment">#取得判别器判别的生成的手写数字的结果</span></span><br><span class="line"> </span><br><span class="line">D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real))) <span class="comment">#对判别器对真实样本的判别结果计算误差(将结果与1比较)</span></span><br><span class="line">D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake))) <span class="comment">#对判别器对虚假样本(即生成器生成的手写数字)的判别结果计算误差(将结果与0比较)</span></span><br><span class="line">D_loss = D_loss_real + D_loss_fake <span class="comment">#判别器的误差</span></span><br><span class="line">G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake))) <span class="comment">#生成器的误差(将判别器返回的对虚假样本的判别结果与1比较)</span></span><br><span class="line"> </span><br><span class="line">dreal_loss_sum = tf.summary.scalar(<span class="string">"dreal_loss"</span>, D_loss_real) <span class="comment">#记录判别器判别真实样本的误差</span></span><br><span class="line">dfake_loss_sum = tf.summary.scalar(<span class="string">"dfake_loss"</span>, D_loss_fake) <span class="comment">#记录判别器判别虚假样本的误差</span></span><br><span class="line">d_loss_sum = tf.summary.scalar(<span class="string">"d_loss"</span>, D_loss) <span class="comment">#记录判别器的误差</span></span><br><span class="line">g_loss_sum = tf.summary.scalar(<span class="string">"g_loss"</span>, G_loss) <span class="comment">#记录生成器的误差</span></span><br><span class="line"> </span><br><span class="line">summary_writer = tf.summary.FileWriter(<span class="string">'snapshots/'</span>, graph=tf.get_default_graph()) <span class="comment">#日志记录器</span></span><br><span class="line"> </span><br><span class="line">D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D) <span class="comment">#判别器的训练器</span></span><br><span class="line">G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G) <span class="comment">#生成器的训练器</span></span><br><span class="line"> </span><br><span class="line">mb_size = <span class="number">128</span> <span class="comment">#训练的batch_size</span></span><br><span class="line">Z_dim = <span class="number">100</span> <span class="comment">#生成器输入的随机噪声的列的维度</span></span><br><span class="line"> </span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=<span class="literal">True</span>) <span class="comment">#mnist是手写数字数据集</span></span><br><span class="line"> </span><br><span class="line">sess = tf.Session() <span class="comment">#会话层</span></span><br><span class="line">sess.run(tf.global_variables_initializer()) <span class="comment">#初始化所有可训练参数</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'out/'</span>): <span class="comment">#初始化训练过程中的可视化结果的输出文件夹</span></span><br><span class="line">    os.makedirs(<span class="string">'out/'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">'snapshots/'</span>): <span class="comment">#初始化训练过程中的模型保存文件夹</span></span><br><span class="line">    os.makedirs(<span class="string">'snapshots/'</span>)</span><br><span class="line"> </span><br><span class="line">saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=<span class="number">50</span>) <span class="comment">#模型的保存器</span></span><br><span class="line"> </span><br><span class="line">i = <span class="number">0</span> <span class="comment">#训练过程中保存的可视化结果的索引</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">1000000</span>): <span class="comment">#训练100万次</span></span><br><span class="line">    <span class="keyword">if</span> it % <span class="number">1000</span> == <span class="number">0</span>: <span class="comment">#每训练1000次就保存一下结果</span></span><br><span class="line">        samples = sess.run(G_sample, feed_dict=&#123;Z: sample_Z(<span class="number">16</span>, Z_dim)&#125;)</span><br><span class="line"> </span><br><span class="line">        fig = plot(samples) <span class="comment">#通过plot函数生成可视化结果</span></span><br><span class="line">        plt.savefig(<span class="string">'out/&#123;&#125;.png'</span>.format(str(i).zfill(<span class="number">3</span>)), bbox_inches=<span class="string">'tight'</span>) <span class="comment">#保存可视化结果</span></span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        plt.close(fig)</span><br><span class="line"> </span><br><span class="line">    X_mb, _ = mnist.train.next_batch(mb_size) <span class="comment">#得到训练一个batch所需的真实手写数字(作为判别器的输入)</span></span><br><span class="line"> </span><br><span class="line">    <span class="comment">#下面是得到训练一次的结果，通过sess来run出来</span></span><br><span class="line">    _, D_loss_curr, dreal_loss_sum_value, dfake_loss_sum_value, d_loss_sum_value = sess.run([D_solver, D_loss, dreal_loss_sum, dfake_loss_sum, d_loss_sum], feed_dict=&#123;X: X_mb, Z: sample_Z(mb_size, Z_dim)&#125;)</span><br><span class="line">    _, G_loss_curr, g_loss_sum_value = sess.run([G_solver, G_loss, g_loss_sum], feed_dict=&#123;Z: sample_Z(mb_size, Z_dim)&#125;)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> it%<span class="number">100</span> ==<span class="number">0</span>: <span class="comment">#每过100次记录一下日志，可以通过tensorboard查看</span></span><br><span class="line">        summary_writer.add_summary(dreal_loss_sum_value, it)</span><br><span class="line">        summary_writer.add_summary(dfake_loss_sum_value, it)</span><br><span class="line">        summary_writer.add_summary(d_loss_sum_value, it)</span><br><span class="line">        summary_writer.add_summary(g_loss_sum_value, it)</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span> it % <span class="number">1000</span> == <span class="number">0</span>: <span class="comment">#每训练1000次输出一下结果</span></span><br><span class="line">        save(saver, sess, <span class="string">'snapshots/'</span>, it)</span><br><span class="line">        print(<span class="string">'Iter: &#123;&#125;'</span>.format(it))</span><br><span class="line">        print(<span class="string">'D loss: &#123;:.4&#125;'</span>. format(D_loss_curr))</span><br><span class="line">        print(<span class="string">'G_loss: &#123;:.4&#125;'</span>.format(G_loss_curr))</span><br><span class="line">        print()</span><br></pre></td></tr></table></figure>
<p>利用 Tensorboard工具，可以将训练过程可视化：</p>
<p>判别器损失：</p>
<p><img src="/2019/08/14/基于Tensorflow的GAN生成手写数字识别/Users\dufub\Desktop\Leselier\source\_posts\基于Tensorflow的GAN生成手写数字识别\1.png" alt></p>
<p>生成器损失：</p>
<p><img src="/2019/08/14/基于Tensorflow的GAN生成手写数字识别/Users\dufub\Desktop\Leselier\source\_posts\基于Tensorflow的GAN生成手写数字识别\2.png" alt></p>
<p>在训练的后期(训练2w次之后)，大家从生成器的误差曲线可以看出，生成器的误差陡增，生成效果也相应变差了(如下图所示)，这是<strong>生成器与判别器失衡</strong>的结果。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Leselier.github.io/2019/08/13/Leetcode-C-1-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leselier">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/abc.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leselier's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/13/Leetcode-C-1-3/" itemprop="url">Leetcode|C++(1-3)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-13T19:32:25+08:00">
                2019-08-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>1、Two Sum（二分查找思想）</p>
<p>给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。</p>
<p>你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。</p>
<p>示例:</p>
<blockquote>
<p>给定 nums = [2, 7, 11, 15], target = 9</p>
<p>因为 nums[0] + nums[1] = 2 + 7 = 9<br>所以返回 [0, 1]</p>
</blockquote>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; twoSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;num = nums;</span><br><span class="line">        <span class="comment">//整体复制</span></span><br><span class="line">        <span class="built_in">std</span>::sort(num.begin(),num.end());</span><br><span class="line">        <span class="comment">//排序</span></span><br><span class="line">        <span class="keyword">int</span> length = nums.size();</span><br><span class="line">        <span class="comment">//返回容器内元素个数</span></span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;::iterator prior = num.begin();</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;::iterator behind= --num.end();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;index;</span><br><span class="line">        <span class="keyword">while</span>(prior&lt;behind)</span><br><span class="line">        &#123;</span><br><span class="line">            sum = *prior+*behind;</span><br><span class="line">            <span class="keyword">if</span>(sum==target)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;length;++i)</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="keyword">if</span>(nums[i]==*prior)</span><br><span class="line">                        index.push_back(i);</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(nums[i]==*behind)</span><br><span class="line">                        index.push_back(i);</span><br><span class="line">                    <span class="keyword">if</span>(index.size()==<span class="number">2</span>)</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(sum&gt;target)</span><br><span class="line">                --behind;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                ++prior;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> index;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>2、Add Two Numbers</p>
<p>给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。</p>
<p>如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。</p>
<p>您可以假设除了数字 0 之外，这两个数都不会以 0 开头。</p>
<p>示例：</p>
<blockquote>
<p>输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)<br>输出：7 -&gt; 0 -&gt; 8<br>原因：342 + 465 = 807</p>
</blockquote>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * struct ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode *next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">ListNode* <span class="title">addTwoNumbers</span><span class="params">(ListNode* l1, ListNode* l2)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="function">ListNode <span class="title">header</span><span class="params">(<span class="number">-1</span>)</span></span>;  </span><br><span class="line">        ListNode* pa = l1;</span><br><span class="line">        ListNode* pb = l2;</span><br><span class="line">        ListNode *latter_ListNode = &amp;header;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> temp_value =<span class="number">0</span>;      </span><br><span class="line">        <span class="keyword">int</span> carry_bit =<span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> ( ; pa !=<span class="literal">NULL</span> || pb !=<span class="literal">NULL</span>; )</span><br><span class="line">        &#123;</span><br><span class="line">             </span><br><span class="line">            </span><br><span class="line">           <span class="keyword">if</span> (pa !=<span class="literal">NULL</span> &amp;&amp; pb !=<span class="literal">NULL</span>) </span><br><span class="line">           &#123;</span><br><span class="line">                   temp_value = (pa-&gt;val + pb-&gt;val + carry_bit) % <span class="number">10</span> ;</span><br><span class="line">                   carry_bit = (pa-&gt;val + pb-&gt;val + carry_bit) / <span class="number">10</span> ;</span><br><span class="line">                   latter_ListNode -&gt; next =  <span class="keyword">new</span> ListNode(temp_value);</span><br><span class="line">                   pa = pa-&gt;next;</span><br><span class="line">                   pb = pb-&gt;next; </span><br><span class="line">           &#125;</span><br><span class="line">       </span><br><span class="line">            </span><br><span class="line">           <span class="keyword">else</span> <span class="keyword">if</span> (pa ==<span class="literal">NULL</span> &amp;&amp; pb !=<span class="literal">NULL</span>)</span><br><span class="line">           &#123;</span><br><span class="line">                   temp_value = (<span class="number">0</span> + pb-&gt;val + carry_bit) % <span class="number">10</span> ;</span><br><span class="line">                   carry_bit = (<span class="number">0</span> + pb-&gt;val + carry_bit) / <span class="number">10</span> ;</span><br><span class="line">                   latter_ListNode -&gt; next =  <span class="keyword">new</span> ListNode(temp_value);    </span><br><span class="line">                   pb = pb-&gt;next; </span><br><span class="line">               </span><br><span class="line">           &#125;</span><br><span class="line">            </span><br><span class="line">          <span class="keyword">else</span> <span class="keyword">if</span> (pa !=<span class="literal">NULL</span> &amp;&amp; pb ==<span class="literal">NULL</span>)</span><br><span class="line">           &#123;</span><br><span class="line">                   temp_value = (pa-&gt;val + <span class="number">0</span> + carry_bit) % <span class="number">10</span> ;</span><br><span class="line">                   carry_bit = (pa-&gt;val + <span class="number">0</span> + carry_bit) / <span class="number">10</span> ;</span><br><span class="line">                   latter_ListNode -&gt; next = <span class="keyword">new</span> ListNode(temp_value);</span><br><span class="line">                   pa = pa-&gt;next; </span><br><span class="line">               </span><br><span class="line">           &#125; </span><br><span class="line">            </span><br><span class="line">          latter_ListNode =  latter_ListNode -&gt; next;         </span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (carry_bit &gt; <span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                latter_ListNode -&gt; next =  <span class="keyword">new</span>  ListNode(carry_bit);</span><br><span class="line">            &#125;</span><br><span class="line">    </span><br><span class="line">      <span class="keyword">return</span> header.next;  </span><br><span class="line">               </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>3、Longest Substring Without Repeating Characters</p>
<p>给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。</p>
<p>示例 1:</p>
<blockquote>
<p>输入: “abcabcbb”<br>输出: 3<br>解释: 因为无重复字符的最长子串是 “abc”，所以其长度为 3。</p>
</blockquote>
<p>示例 2:</p>
<blockquote>
<p>输入: “bbbbb”<br>输出: 1<br>解释: 因为无重复字符的最长子串是 “b”，所以其长度为 1。</p>
</blockquote>
<p>示例 3:</p>
<blockquote>
<p>输入: “pwwkew”<br>输出: 3<br>解释: 因为无重复字符的最长子串是 “wke”，所以其长度为 3。<br>     请注意，你的答案必须是 子串 的长度，”pwke” 是一个子序列，不是子串。</p>
</blockquote>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//解题思路类似于kmp算法</span></span><br><span class="line">        <span class="built_in">map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; last_appear_index;</span><br><span class="line">        <span class="comment">//键-值对的集合,这里存储字母于最后出现位置的关系</span></span><br><span class="line">        <span class="keyword">int</span> substring_start = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//子串开始的位置</span></span><br><span class="line">        <span class="keyword">int</span> max_length = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//定义最长子串的长度</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">map</span>&lt;<span class="keyword">char</span>, <span class="keyword">int</span>&gt;::iterator  map_it;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> len = s.length();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; len; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            map_it = last_appear_index.find(s[i]);</span><br><span class="line">            <span class="comment">//检测s[i]是否存在</span></span><br><span class="line">            <span class="keyword">if</span>(map_it!=last_appear_index.end() &amp;&amp; map_it-&gt;second&gt;=substring_start)&#123;</span><br><span class="line">               <span class="comment">//遇到的是重复字母</span></span><br><span class="line">               substring_start = map_it-&gt;second + <span class="number">1</span>;</span><br><span class="line">               <span class="comment">//以上一个重复字母的index+1作为新的搜索起始位置</span></span><br><span class="line">            &#125;</span><br><span class="line">            last_appear_index[s[i]] = i;</span><br><span class="line">            <span class="comment">//更新新的索引</span></span><br><span class="line">            max_length = max(max_length,i - substring_start +<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> max_length;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Leselier.github.io/2019/08/13/差分隐私论文解读-GENERATING-DIFFERENTIALLY-PRIVATE-DATASETS-USING-GANS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leselier">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/abc.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leselier's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/13/差分隐私论文解读-GENERATING-DIFFERENTIALLY-PRIVATE-DATASETS-USING-GANS/" itemprop="url">差分隐私论文解读|GENERATING DIFFERENTIALLY PRIVATE DATASETS USING GANS</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-13T16:55:51+08:00">
                2019-08-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>一、基本信息</p>
<p>会议：ICLR 2018 Conference Blind Submission</p>
<p>二、研究背景</p>
<p>随着深度学习的发展，深度学习所需要的大量数据也造成隐私泄漏的风险，比如，通过生成数据还原训练集的真实数据。为了在利用机器学习的方法的同时也能保护隐私数据，目前已经开发了一系列的技术，但目前来说，差分隐私是隐私保护效果最好的一种技术。</p>
<p>三、创新点</p>
<p>1、我们提出了一种新的非交互式差异隐私数据发布机制，以及据我们所知，这是复杂现实世界数据的第一个实用的解决方案；</p>
<p>2、我们引入了一种新技术，通过在前馈网络训练过程中增加噪声来进行隐私保护；</p>
<p>3、我们证明这种技术可以保证所有的输出和神经网络中的学习到的权重可以保证差分隐私；</p>
<p>4、我们证明我们能够在保持合理隐私预算的同时实现学习任务的高准确性。</p>
<p>四、详解</p>
<p>1、GAN的介绍</p>
<p>一个生成网络与一个判别网络组成。生成网络从潜在空间（latent space）中随机取样作为输入，其输出结果需要尽量模仿训练集中的真实样本。判别网络的输入则为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能分辨出来。而生成网络则要尽可能地欺骗判别网络。两个网络相互对抗、不断调整参数，最终目的是使判别网络无法判断生成网络的输出结果是否真实。</p>
<p>2、差分隐私</p>
<p>给定一个具有差分隐私的算法 $A_p(\cdot)$ 。该算法是一种随机化算法，目的是为了让观察者难以重构输入数据，其中观察者是任何使用数据获取算法输出的人。差异隐私的定义：</p>
<p>Definition 3.1：设有随机化算法 $A_p$ 提供 ($\epsilon$,$\delta$) 差分隐私保护，对于任何两个兄弟数据集 $D$ 和 $D^{\prime}$ （它们之间相差一条数据）和任何一个输出子集 $S$ ，满足：</p>
<script type="math/tex; mode=display">
P(A_P(D)\in S)\leqslant e^{\epsilon}\cdot P(A_P(D^\prime)\in S) + \delta</script><p>可以得到这个定义等价于：</p>
<script type="math/tex; mode=display">
|log(\frac{P(A_P(D)=s)}{P(A_P(D^\prime)= s)})|\leqslant \epsilon</script><p>并且有 $1-\delta$ 的可能性 $s$ 在输出范围，$\epsilon$ 反应了隐私水平，$\epsilon$ 越小，表示在两个数据集上的输出差别小，说明具有较高的数据扰动，但隐私保护程度高。没有隐私保护的话，$\epsilon=\infty$  。</p>
<p>实现差分隐私最广泛使用的两种机制是拉普拉斯算子和高斯噪声，我们在这里使用高斯噪声机制，高斯噪声机制定义：</p>
<script type="math/tex; mode=display">
M(d)\triangleq f(d)+N(0,s^2_f\sigma^2)</script><p>这里 $s_f$是差分隐私的敏感度，$s_f=|f(d)-f(d^\prime)|$ 。</p>
<p>3、具体方法</p>
<p>需要实现的目标：</p>
<p>给定一个数据集 $X\sim p_{data}(x)$，利用差分隐私机制 $M$ 生成一个人工数据集 $\widetilde{X} = M(X)$。</p>
<p>-数据分布相似或相同 $\widetilde{X}\sim p_{data}(x)$</p>
<p>-对任意相邻数据集 $X,X^\prime$ 提供差分隐私保护 $P(M(X)\in S)\leqslant e^{\epsilon}\cdot P(M(X^\prime)\in S) + \delta$</p>
<p>为了实现差分隐私，我们采用如下的办法：</p>
<p><img src="/2019/08/13/差分隐私论文解读-GENERATING-DIFFERENTIALLY-PRIVATE-DATASETS-USING-GANS/Users\dufub\Desktop\Leselier\source\_posts\差分隐私论文解读-GENERATING-DIFFERENTIALLY-PRIVATE-DATASETS-USING-GANS\1.png" alt></p>
<p>在GAN的判别器神经网络中引入噪声层，以致于使它的输出和生成器神经网络的权重满足差分隐私，这样，我们可以利用生成器生成可以用于发布的满足差分隐私的数据集。</p>
<p>4、理论分析，只要我们高斯噪声层 $Y\sim N(0,\sigma^2)$ 满足 $\sigma \ge C\sqrt{2log(1.25/\delta)}/\epsilon$ ，就能满足 $(\epsilon,\delta)-$差分隐私。</p>
<p>这里 $C$ 是查询函数的敏感度。</p>
<p>证明：满足 $(\epsilon,\delta)-$差分隐私即</p>
<script type="math/tex; mode=display">
|ln\frac{e^{-\frac{1}{2\sigma^2}x^2}}{e^{-\frac{1}{2\sigma^2}(x+\triangle f)^2}}|=|\frac{1}{2\sigma^2}(2x\triangle f+(\triangle f)^2)|\le \epsilon\\
\therefore|x| \le \frac{\sigma^2\epsilon}{\triangle f}-\frac{\triangle f}{2}</script><p>令 $t=\frac{\sigma^2\epsilon}{\triangle f}-\frac{\triangle f}{2}$ ，当且仅当 $||x||\le t$ 时，该分布是满足 $(\epsilon,\delta)-$差分隐私的，而当 $||x||&gt;t$ 时为隐私泄露，我们希望隐私泄露的概率小于 $\delta$ ，即</p>
<script type="math/tex; mode=display">
P(|x|>t)<\delta \\
P(x>t)<\frac{\delta}{2}</script><p>又有</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{split}
P(x>t)&=\frac{1}{\sqrt{2\pi\sigma}}\int_t ^{\infty} e^{-\frac{x^2}{2\sigma^2}}dx \\
&<\frac{1}{\sqrt{2\pi\sigma}}\int_t ^{\infty} \frac{x}{t}e^{-\frac{x^2}{2\sigma^2}}dx  ~~【因为x>t】\\
&=\frac{\sigma}{\sqrt{2\pi}t}e^{-\frac{t^2}{2\sigma^2}}
\end{split}
\end{equation}</script><p>那么问题转化为</p>
<script type="math/tex; mode=display">
\frac{\sigma}{\sqrt{2\pi}t}e^{-\frac{t^2}{2\sigma^2}}<\frac{\delta}{2} \\
\frac{t}{\sigma}e^{-\frac{t^2}{2\sigma^2}}>\frac{2}{\sqrt{2\pi}\delta} \\
ln\frac{t}{\sigma}+\frac{t^2}{2\sigma^2}>ln\frac{2}{\sqrt{2\pi}t}</script><p>将上式按下面的方法拆开：</p>
<script type="math/tex; mode=display">
\begin{equation}
\left\{
\begin{array}{**lr**}
ln\frac{t}{\sigma}\ge0 \\
\frac{t^2}{2\sigma^2}>ln\frac{2}{\sqrt{2\pi}t}
\end{array}
\right.
\end{equation}</script><p>由于 $t=\frac{\sigma^2\epsilon}{\triangle f}-\frac{\triangle f}{2}$ ，若令 $\sigma=C\frac{\triangle f}{\epsilon}$ ，那么 $t=C\sigma-\frac{\triangle f}{2}$ 。得：</p>
<script type="math/tex; mode=display">
\frac{t}{\sigma} = c-\frac{\epsilon}{2C}\\
\epsilon <1，C\ge1  \\
ln(C-\frac\epsilon {2c})>ln(c-\frac{1}{2})\ge0 \\
\therefore C\ge\frac{3}{2}</script><p>又：</p>
<script type="math/tex; mode=display">
\frac{t^2}{2\sigma^2}=\frac{1}{2}(C-\frac{\epsilon}{2C})^2=\frac{1}{2}(C^2-\epsilon+\frac{\epsilon^2}{4C^2})</script><p>因为$\epsilon&lt;1，C\ge\frac{3}{2}$</p>
<script type="math/tex; mode=display">
C^2-\epsilon+\frac{\epsilon^2}{4C^2}>C^2-\frac{8}{9}>2ln\frac{2}{\sqrt{2\pi}\delta} \\
C^2>ln\frac 2 \pi e^{\frac8 9}+2ln\frac{1}{\delta} \\
\because ln\frac 2 \pi e^{\frac8 9}>1.25^2 \\
\therefore C^2>2ln\frac{1.25}{\delta}</script><p>又 <script type="math/tex">\sigma=C\frac{\triangle f}{\epsilon}</script> ，所以可以得到 $\sigma \ge C\sqrt{2log(1.25/\delta)}/\epsilon$ 。</p>
<p>五、实验</p>
<p>基于MNIST数据集和SVHN数据集</p>
<p><img src="/2019/08/13/差分隐私论文解读-GENERATING-DIFFERENTIALLY-PRIVATE-DATASETS-USING-GANS/Users\dufub\Desktop\Leselier\source\_posts\差分隐私论文解读-GENERATING-DIFFERENTIALLY-PRIVATE-DATASETS-USING-GANS\2.png" alt></p>
<p>在分类器中的表现为：</p>
<p><img src="/2019/08/13/差分隐私论文解读-GENERATING-DIFFERENTIALLY-PRIVATE-DATASETS-USING-GANS/Users\dufub\Desktop\Leselier\source\_posts\差分隐私论文解读-GENERATING-DIFFERENTIALLY-PRIVATE-DATASETS-USING-GANS\3.png" alt></p>
<p>六、结论与思考</p>
<p>通过差分隐私保证非交互式私有数据发布的问题。我们使用生成对抗网络来生成人工隐私保护数据集。对于深度学习中现有的隐私保护工作，该方法允许发布已清理的数据并在其上训练任何非私有模型。选择GAN作为生成模型可确保可扩展性，并使该技术适用于结构复杂的真实数据。此外，此方法不需要在释放之前对生成的数据运行隐私测试。</p>
<p>此外，我们引入了一种新方法，用于保护深度神经网络特有的训练数据的隐私，这是在数据空间中添加噪声。它提供差分隐私保证，允许以简单直接的方式构建隐私保护模型，而无需修改优化算法。</p>
<p>在我们的实验中，我们表明，训练人工数据的学生模型可以在MNIST数据集上实现高效用，同时保持可接受的隐私性和灵活性的性能成本更复杂的SVHN数据的水平。直接向受过训练的模型添加隐私仍然提供更好的准确性。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Leselier.github.io/2019/08/12/论文解读——WGAN相关/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leselier">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/abc.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leselier's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/12/论文解读——WGAN相关/" itemprop="url">论文解读——WGAN相关</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-12T17:03:52+08:00">
                2019-08-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Wasserstein-GAN"><a href="#Wasserstein-GAN" class="headerlink" title="Wasserstein GAN"></a>Wasserstein GAN</h3><h4 id="一、基本信息"><a href="#一、基本信息" class="headerlink" title="一、基本信息"></a>一、基本信息</h4><p>会议：ICML 2017 </p>
<h4 id="二、研究背景"><a href="#二、研究背景" class="headerlink" title="二、研究背景"></a>二、研究背景</h4><p>自从GAN在2014年提出以来，GAN就存在着训练困难、生成器和判别器的loss无法指示训练进程、生成样本缺乏多样性等问题。从那时起，很多论文都在尝试解决，但是效果不尽人意，比如最有名的一个改进<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1511.06434" target="_blank" rel="noopener">DCGAN</a>依靠的是对判别器和生成器的架构进行实验枚举，最终找到一组比较好的网络架构设置，但是实际上是治标不治本，没有彻底解决问题。</p>
<h4 id="三、创新点"><a href="#三、创新点" class="headerlink" title="三、创新点"></a>三、创新点</h4><p>Wasserstein GAN（WGAN）成功地做到了以下几点：</p>
<p>1、彻底解决GAN训练不稳定的问题，不再需要平衡生成器和判别器的训练程度</p>
<p>2、基本解决了collapse mode的问题，确保了生成样本的多样性 </p>
<p>3、训练过程中终于有一个像交叉熵、准确率这样的数值来指示训练的进程，这个数值越小代表GAN训练得越好，代表生成器产生的图像质量越高</p>
<p>4、以上一切好处不需要精心设计的网络架构，最简单的多层全连接网络就可以做到</p>
<h4 id="四、详解"><a href="#四、详解" class="headerlink" title="四、详解"></a>四、详解</h4><h5 id="1、原始GAN存在的问题"><a href="#1、原始GAN存在的问题" class="headerlink" title="1、原始GAN存在的问题"></a>1、原始GAN存在的问题</h5><p>原始GAN中判别器要最小化如下损失函数，尽可能把真实样本分为正例，生成样本分为负例：</p>
<script type="math/tex; mode=display">
-E_{x\thicksim P_{r}}[log(D(x))]-E_{x\thicksim P_{g}}[log(1-D(x)] ~~~~~~~~~~~~~~~~~~~~~(1)</script><p>其中，$P_r$ 是真实样本分布，$P_g$ 是由生成器产生的样本分布。</p>
<p>那么，生成器的损失函数为</p>
<script type="math/tex; mode=display">
E_{x\thicksim P_{g}}[log(1-D(x)]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(2)</script><hr>
<hr>
<p><strong>原始GAN存在的第一个问题是</strong>：判别器越好，生成器梯度消失越严重。</p>
<p>从公式(1)得到，对于一个具体的样本 $x$ ，它可能来自真实分布也可能来自生成分布，它对公式(1)的损失函数的贡献是</p>
<script type="math/tex; mode=display">
-P_r(x)logD(x)-P_g(x)log[1-D(x)]~~~~~~~~~~~~~~~~~~~~~~~~~~~~(3)</script><p>令其关于 $D(x)$ 的导数为 0，得</p>
<script type="math/tex; mode=display">
-\frac{P_r(x)}{D(x)}+\frac{P_g(x)}{1-D(x)}=0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(4)</script><p>解得最优判别器为</p>
<script type="math/tex; mode=display">
D^*(x)=\frac{P_r(x)}{P_r(x)+P_g(x)}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(5)</script><p>这个结果从直观上很容易理解，就是看一个样本 $x$ 来自真实分布和生成分布的可能性的相对比例。如果 $P_r(x)=0$ 且 $P_g(x)\ne0$ ，最优判别器就应该非常自信地给出概率0；如果 $P_r(x)=P_g(x)$ ，说明该样本是真是假的可能性刚好都是一半，此时最优判别器也应该给出概率0.5。</p>
<p>那么，为什么判别器越好，生成器的loss降不下去、生成器梯度消失越严重？</p>
<p>我们探究一下在极端情况——判别器最优的时候，生成器的损失函数变成什么。给公式2加上一个不依赖于生成器的项，使之变成</p>
<script type="math/tex; mode=display">
E_{x\thicksim P_{r}}[log(D(x))]+E_{x\thicksim P_{g}}[log(1-D(x)] ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(6)</script><p>由于最小化公式(6)这个损失函数等价于最小化 $E_{x\thicksim P_{g}}[log(1-D(x)]$ ，而且它刚好是判别器损失函数的反。代入最优判别器即公式(3)，再进行简单的变换可以得到</p>
<script type="math/tex; mode=display">
E_{x\thicksim P_{r}}log\frac{P_r(x)}{\frac{1}{2}[P_r(x)+P_g(x)]}+E_{x\thicksim P_{g}}log\frac{P_g(x)}{\frac{1}{2}[P_r(x)+P_g(x)]}-2log2~~~~~(7)</script><p>此处，我们引入 $KL$散度和 $JS$ 散度：</p>
<p>$KL$散度是是两个概率分布之间差别的非对称性的度量。</p>
<p>$JS$散度是是两个概率分布之间相似度的度量，基于 $KL$散度的变体。</p>
<script type="math/tex; mode=display">
KL(P_1||P_2)=E_{x\thicksim P_{1}}log\frac{P_1}{P_2}~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(8)</script><script type="math/tex; mode=display">
JS(P_1||P_2)=\frac{1}{2}KL(P_1||\frac{P_1+P_2}{2})+\frac{1}{2}KL(P_2||\frac{P_1+P_2}{2})~~~~~~~~~~~~~~~~~(9)</script><p>公式(7)也就是</p>
<script type="math/tex; mode=display">
2JS(P_r||P_g)-2log2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(10)</script><p>也就是说，目前可以得到结论：在生成器最优的情况下，我们的损失函数可以变换为真实分布$P_r$和生成分布$P_g$之间的$JS$散度，因为我们的判别器越优，最小化生成器的损失函数就会越近似于最小化$P_r$和$P_g$之间的$JS$散度。</p>
<p>我们希望如果两个分布之间越接近它们的$JS$散度越小，我们通过优化$JS$散度就能将$P_g$去拟合$P_r$，达到以假乱真的目的。这个希望在两个分布有所重叠的时候是成立的，但是如果两个分布完全没有重叠的部分，或者它们重叠的部分可忽略（下面解释什么叫可忽略），它们的JS散度是多少呢？</p>
<p>此时，我们对$JS$散度进行计算，由于 $P_1(x)=0$时$P_2(x)\ne0$，$P_1(x)\ne0$时$P_2(x)=0$。可得$log\frac{P_2}{\frac{1}{2}(P_2+0)}=log2$，$log\frac{P_1}{\frac{1}{2}(P_1+0)}=log2$</p>
<p>最终</p>
<script type="math/tex; mode=display">
JS(P_1||P_2)=log2</script><p>也就是说，只要$P_r$与$P_g$没有一点重叠或者重叠部分可忽略，JS散度就固定是常数$log2$，那么对于梯度下降来说梯度为0。</p>
<p>但是 $P_r$ 与 $P_g$ 不重叠的可能性非常大：</p>
<ul>
<li>首先，$P_r$与$P_g$之间几乎不可能有不可忽略的重叠，所以无论它们之间的“缝隙”多狭小，都肯定存在一个最优分割曲面把它们隔开，最多就是在那些可忽略的重叠处隔不开而已。</li>
<li>由于判别器作为一个神经网络可以无限拟合这个分隔曲面，所以存在一个最优判别器，对几乎所有真实样本给出概率1，对几乎所有生成样本给出概率0，而那些隔不开的部分就是难以被最优判别器分类的样本，但是它们的测度为0，可忽略。</li>
<li>最优判别器在真实分布和生成分布的支撑集上给出的概率都是常数（1和0），导致生成器的loss梯度为0，梯度消失。</li>
</ul>
<p>有了这些理论分析，原始GAN不稳定的原因就彻底清楚了：判别器训练得太好，生成器梯度消失，生成器loss降不下去；判别器训练得不好，生成器梯度不准，四处乱跑。只有判别器训练得不好不坏才行，但是这个火候又很难把握，甚至在同一轮训练的前后不同阶段这个火候都可能不一样，所以GAN才那么难训练。</p>
<p>实例：</p>
<p>损失函数值的变化：</p>
<p><img src="/2019/08/12/论文解读——WGAN相关/11.png" alt></p>
<p><img src="/2019/08/12/论文解读——WGAN相关/12.png" alt></p>
<p><img src="/2019/08/12/论文解读——WGAN相关/13.png" alt></p>
<p><strong>原始GAN的第二个问题</strong>：多样性问题：</p>
<p>该推导依然在判别器最优的情况下：</p>
<script type="math/tex; mode=display">
E_{x\thicksim P_{r}}[logD^*(x)]+E_{x\thicksim P_{g}}[log(1-D^*(x)]=2JS(P_r||P_g)-2log2~~~~~~~~~~~~(11)</script><p>我们把$KL$散度变换成含$D^*$的形式：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{split}
KL(P_g||P_r)&=E_{x\thicksim P_{g}}[log\frac{P_g(x)}{P_r(x)}]\\
&=E_{x\thicksim P_{g}}[log\frac{P_g(x)/(P_r(x)+P_g(x))}{P_r(x)/(P_r(x)+P_g(x))}]\\
&=E_{x\thicksim P_{g}}[log\frac{1-D^*(x)}{D^*(x)}]\\
&=E_{x\thicksim P_{g}}log[1-D^*(x)]-E_{x\thicksim P_{g}}logD^*(x)
\end{split}
\end{equation}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(12)</script><p>公式(11)、(12)联立得最小化生成器目标的等价变形为：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{split}
E_{x\thicksim P_{g}}[-logD^*(x)]&=KL(P_g||P_r)-E_{x\thicksim P_{g}}log[1-D^*(x)]\\
&=KL(P_g||P_r)-2JS(P_r||P_g)+2log2+E_{x\thicksim P_{r}}[logD^*(x)]~~ ~~(13)
\end{split}
\end{equation}</script><p>注意上式最后两项不依赖于生成器G，最终得到最小化生成器目标函数$E_{x\thicksim P_{g}}[-logD^*(x)]$等价于最小化</p>
<script type="math/tex; mode=display">
KL(P_g||P_r)-2JS(P_r||P_g)~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(14)</script><p>这个等价最小化目标存在两个严重的问题。</p>
<p>第一是它同时要最小化生成分布与真实分布的KL散度，却又要最大化两者的JS散度，一个要拉近，一个却要推远！这在直观上非常荒谬，在数值上则会导致梯度不稳定，这是后面那个JS散度项的毛病。</p>
<p>第二，即便是前面那个正常的KL散度项也有毛病。因为KL散度不是一个对称的衡量。也就是说：$KL(P_g||P_r)$和$KL(P_r||P_g)$是不一样的：</p>
<ul>
<li>当$P_g(x)\to 0$而$P_r(x)\to1$时，$P_g(x)log\frac{P_g(x)}{P_r(x)}\to 0$，对$KL(P_g||P_r)$贡献趋近0</li>
<li>当$P_g(x)\to 1$而$P_r(x)\to0$时，$P_g(x)log\frac{P_g(x)}{P_r(x)}\to +\infty$，对$KL(P_g||P_r)$贡献趋近正无穷</li>
</ul>
<p>第一种情况代表：生成器没能生成真实的样本，惩罚微小；</p>
<p>第二种情况代表：生成器生成了不真实的样本，惩罚巨大。</p>
<p>第一种错误对应的是缺乏多样性，第二种错误对应的是缺乏准确性。</p>
<p><strong>这一放一打之下，生成器宁可多生成一些重复但是很“安全”的样本，也不愿意去生成多样性的样本，因为那样一不小心就会产生第二种错误，得不偿失。这种现象就是大家常说的collapse mode</strong></p>
<p><img src="/2019/08/12/论文解读——WGAN相关/22.png" alt></p>
<p>训练到后面</p>
<p><img src="/2019/08/12/论文解读——WGAN相关/21.png" alt></p>
<p>那么原始GAN问题的根源可以归结为两点，一是等价优化的距离衡量（KL散度、JS散度）不合理，二是生成器随机初始化后的生成分布很难与真实分布有不可忽略的重叠。</p>
<h5 id="2、WGAN之前的一个过渡解决方案"><a href="#2、WGAN之前的一个过渡解决方案" class="headerlink" title="2、WGAN之前的一个过渡解决方案"></a>2、WGAN之前的一个过渡解决方案</h5><p>对生成样本和真实样本加噪声，直观上说，使得原本的两个低维流形“弥散”到整个高维空间，强行让它们产生不可忽略的重叠。而一旦存在重叠，JS散度就能真正发挥作用，此时如果两个分布越靠近，它们“弥散”出来的部分重叠得越多，JS散度也会越小而不会一直是一个常数，于是（在第一种原始GAN形式下）梯度消失的问题就解决了。在训练过程中，我们可以对所加的噪声进行退火（annealing），慢慢减小其方差，到后面两个低维流形“本体”都已经有重叠时，就算把噪声完全拿掉，JS散度也能照样发挥作用，继续产生有意义的梯度把两个低维流形拉近，直到它们接近完全重合。</p>
<p>但是，因为加噪JS散度的具体数值受到噪声的方差影响，随着噪声的退火，前后的数值就没法比较了，所以它不能成为$P_r$和$P_g$距离的本质性衡量。</p>
<h5 id="3、Wasserstein距离"><a href="#3、Wasserstein距离" class="headerlink" title="3、Wasserstein距离"></a>3、Wasserstein距离</h5><p>Wasserstein距离定义如下：</p>
<script type="math/tex; mode=display">
W(P_r,P_g)=\inf\limits_{\gamma\sim\prod(P_r,P_g)}E_{(x,y)\sim\gamma}[||x-y||]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(15)</script><p>其中，$\prod(P_r,P_g)$是$P_r$和$P_g$组合起来的所有可能的联合分布的集合，对于每一个可能的联合分布而言，可以从采样$(x,y)\sim\gamma$得到一个真实样本$x$和一个生成样本$y$，并计算出这对样本的距离$||x-y||$，接着可以计算该联合分布$\gamma$下样本对距离的期望值$E_{(x,y)\sim\gamma}[||x-y||]$。在所有可能的联合分布中对该期望值取得的下界$\inf\limits_{\gamma\sim\prod(P_r,P_g)}E_{(x,y)\sim\gamma}[||x-y||]$就定义为Wasserstein距离。</p>
<p>直观上，理解Wasserstein距离为把$P_g$分布挪到$P_r$分布的位置上的最小消耗。</p>
<p><strong>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近</strong></p>
<p>举例：考虑如下二维空间中的两个分布$P_1$和$P_2$，$P_1$在线段AB上均匀分布，$P_2$在线段CD上均匀分布，通过控制参数$\theta$可以控制着两个分布的距离远近。</p>
<p><img src="/2019/08/12/论文解读——WGAN相关/1.jpg" alt="img"></p>
<p>容易得到</p>
<p>$KL(P_1||P_2)=KL(P_2||P_1)=\begin{cases}+\infty &amp; {if ~\theta\ne 0}\\0 &amp; {if~ \theta= 0}\end{cases}$</p>
<p>$JS(P_1||P_2)=\begin{cases}log2 &amp; {if ~\theta\ne 0}\\0 &amp; {if~ \theta= 0}\end{cases}$</p>
<p>$W(P_1,P_2)=|\theta|$                                                                                                                                    $(16)$</p>
<p>KL散度和JS散度是突变的，要么最大要么最小，<strong>Wasserstein距离却是平滑的</strong>，如果我们要用梯度下降法优化$\theta$这个参数，前两者根本提供不了梯度，Wasserstein距离却可以。类似地，在高维空间中如果两个分布不重叠或者重叠部分可忽略，则KL和JS既反映不了远近，也提供不了梯度，<strong>但是Wasserstein却可以提供有意义的梯度</strong>。</p>
<p>但是Wasserstein距离定义（公式15）中的$\inf\limits_{\gamma\sim\prod(P_r,P_g)}E_{(x,y)\sim\gamma}[||x-y||]$无法直接求解，论文作者利用已有的定理将公式(15)转化为：</p>
<script type="math/tex; mode=display">
W(P_r,P_g)=\frac{1}{K}\sup\limits_{||f||_L\le K}E_{x\sim P_r}[f(x)]-E_{x\sim P_g}[f(x)]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(17)</script><p>这里，需要引入Lipschitz连续的概念，它是一个比通常普通的连续更强的光滑性条件。</p>
<p>它在一个连续函数$f$上面额外施加了一个限制，要求存在一个常数$K\geq 0$使得定义域内的任意两个元素$x_1$和$x_2$都满足</p>
<script type="math/tex; mode=display">
|f(x_1)-f(x_2)|\leq K|x_1-x_2|~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(18)</script><p>$K$叫做函数$f$的Lipschitz常数。</p>
<p>公式(17)的意思就是在要求函数$f$的Lipschitz常数$||f||_L$不超过$K$的条件下，对所有可能满足条件的$f$取到$E_{x\sim P_r}[f(x)]-E_{x\sim P_g}[f(x)]$的上界，然后再除以$K$。特别地，我们可以用一组参数$w$来定义一系列可能的函数$f_w$，此时求解公式(17)可以近似变成求解如下形式</p>
<script type="math/tex; mode=display">
K\cdot W(P_r,P_g)\approx\max\limits_{w:|f_w|_L\le K}E_{x\sim P_r}[f_w(x)]-E_{x\sim P_g}[f_w(x)]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(19)</script><p>我们可以把$f$用一个带参数$w$的神经网络来表示，由于神经网络的拟合能力足够强大，我们有理由相信，这样定义出来的一系列$f_w$虽然无法囊括所有可能，但是也足以高度近似公式(17)要求的那个$sup_{||f||_{L\leq K}}$了。</p>
<p>最后，还不能忘了满足公式(19)中$||f_w||_L\leq K$这个限制。我们其实不关心具体的K是多少，只要它不是正无穷就行，因为它只是会使得梯度变大K倍，并不会影响梯度的方向。所以作者采取了一个非常简单的做法，就是限制神经网络$f_{\theta}$的所有参数$w_i$的不超过某个范围$[-c,c]$，比如$w_i\in[-0.01,0.01]$，此时关于输入样本$x$的导数$\frac{\partial f_w}{\partial x}$也不会超过某个范围，所以一定存在某个不知道的常数K使得$f_w$的局部变动幅度不会超过它，Lipschitz连续条件得以满足。具体在算法实现中，只需要每次更新完$w$后把它clip回这个范围就可以了。</p>
<p>到此为止，我们可以构造一个含参数$w$、最后一层不是非线性激活层的判别器网络$f_w$，在限制$w$不超过某个范围的条件下，使得</p>
<script type="math/tex; mode=display">
L=E_{x\sim P_r}[f_w(x)]-E_{x\sim P_g}[f_w(x)]~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(20)</script><p>尽可能最大，此时$L$就会近似真实分布与生成分布之间的Wasserstein距离（忽略常数倍数K）。注意原始GAN的判别器做的是真假二分类任务，所以最后一层是sigmoid，但是现在WGAN中的判别器$f_w$做的是近似拟合Wasserstein距离，属于回归任务，所以要把最后一层的sigmoid拿掉。</p>
<p>接下来生成器要近似地最小化Wasserstein距离，可以最小化$L$，由于Wasserstein距离的优良性质，我们不需要担心生成器梯度消失的问题。再考虑到$L$的第一项与生成器无关，就得到了WGAN的两个loss。</p>
<p>$-E_{x\sim P_g}[f_w(x)]$                                              (21)  ——WGAN生成器损失函数</p>
<p>$E_{x\sim P_g}[f_w(x)]-E_{x\sim P_r}[f_w(x)]$                 (22)——WGAN判别器损失函数</p>
<p><strong>公式(20)是公式(22)的反，可以指示训练进程，其数值越小，表示真实分布与生成分布的Wasserstein距离越小，GAN训练得越好。</strong></p>
<p>这样，完整的GAN的算法流程为：</p>
<p><img src="/2019/08/12/论文解读——WGAN相关/2.png" alt="1565596501452"></p>
<p>上文说过，WGAN与原始GAN第一种形式相比，只改了四点：</p>
<ul>
<li>判别器最后一层去掉sigmoid</li>
<li>生成器和判别器的loss不取log</li>
<li>每次更新判别器的参数之后把它们的绝对值截断到不超过一个固定常数c</li>
<li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li>
</ul>
<p>前三点都是从理论分析中得到的，已经介绍完毕；第四点却是作者从实验中发现的，属于trick，相对比较“玄”。作者发现如果使用Adam，判别器的loss有时候会崩掉，当它崩掉时，Adam给出的更新方向与梯度方向夹角的cos值就变成负数，更新方向与梯度方向南辕北辙，这意味着判别器的loss梯度是不稳定的，所以不适合用Adam这类基于动量的优化算法。作者改用RMSProp之后，问题就解决了，因为RMSProp适合梯度不稳定的情况。</p>
<h4 id="四、实验结果"><a href="#四、实验结果" class="headerlink" title="四、实验结果"></a>四、实验结果</h4><p>1、判别器所近似的Wasserstein距离与生成器的生成图片质量高度相关</p>
<p><img src="/2019/08/12/论文解读——WGAN相关/3.png" alt="1565596849041"></p>
<p>2、WGAN如果用类似DCGAN架构，生成图片的效果与DCGAN差不多：</p>
<p><img src="/2019/08/12/论文解读——WGAN相关/4.png" alt="1565596921785"></p>
<p>但是厉害的地方在于WGAN不用DCGAN各种特殊的架构设计也能做到不错的效果，比如如果大家一起拿掉Batch Normalization的话，DCGAN就崩了：</p>
<p><img src="/2019/08/12/论文解读——WGAN相关/5.png" alt="1565596970602"></p>
<p>如果WGAN和原始GAN都使用多层全连接网络（MLP），不用CNN，WGAN质量会变差些，但是原始GAN不仅质量变得更差，而且还出现了collapse mode，即多样性不足：</p>
<p><img src="/2019/08/12/论文解读——WGAN相关/6.png" alt="1565597001833"></p>
<h4 id="五、结论与思考"><a href="#五、结论与思考" class="headerlink" title="五、结论与思考"></a>五、结论与思考</h4><p>WGAN前作分析了Ian Goodfellow提出的原始GAN两种形式各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。</p>
<p>WGAN前作针对分布重叠问题提出了一个过渡解决方案，通过对生成样本和真实样本加噪声使得两个分布产生重叠，理论上可以解决训练不稳定的问题，可以放心训练判别器到接近最优，但是未能提供一个指示训练进程的可靠指标，也未做实验验证。</p>
<p>WGAN本作引入了Wasserstein距离，由于它相对KL散度与JS散度具有优越的平滑特性，理论上可以解决梯度消失问题。接着通过数学变换将Wasserstein距离写成可求解的形式，利用一个参数数值范围受限的判别器神经网络来最大化这个形式，就可以近似Wasserstein距离。在此近似最优判别器下优化生成器使得Wasserstein距离缩小，就能有效拉近生成分布与真实分布。WGAN既解决了训练不稳定的问题，也提供了一个可靠的训练进程指标，而且该指标确实与生成样本的质量高度相关。作者对WGAN进行了实验验证。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://Leselier.github.io/2019/08/11/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leselier">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/abc.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leselier's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/11/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-11T14:27:07+08:00">
                2019-08-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/abc.JPG" alt="Leselier">
            
              <p class="site-author-name" itemprop="name">Leselier</p>
              <p class="site-description motion-element" itemprop="description">A master student of JUN</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Leselier" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/5708446219/home" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leselier</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
